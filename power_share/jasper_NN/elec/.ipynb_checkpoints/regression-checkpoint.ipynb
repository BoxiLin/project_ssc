{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(2020)  # for reproducibility\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 87672 samples, validate on 17520 samples\n",
      "Epoch 1/10\n",
      "87672/87672 [==============================] - 6s 70us/step - loss: 860540.7464 - mae: 711.5812 - yearerr: 14097.4424 - val_loss: 1086654.3773 - val_mae: 823.7531 - val_yearerr: 39777.2656\n",
      "Epoch 2/10\n",
      "87672/87672 [==============================] - 6s 68us/step - loss: 501271.4057 - mae: 566.7383 - yearerr: 12188.9209 - val_loss: 1090179.7798 - val_mae: 813.8664 - val_yearerr: 47313.0703\n",
      "Epoch 3/10\n",
      "87672/87672 [==============================] - 6s 68us/step - loss: 399826.9242 - mae: 499.8257 - yearerr: 13130.2988 - val_loss: 494121.5208 - val_mae: 548.3640 - val_yearerr: 27376.9590\n",
      "Epoch 4/10\n",
      "87672/87672 [==============================] - 6s 69us/step - loss: 355443.8342 - mae: 467.3383 - yearerr: 13339.8965 - val_loss: 934967.2443 - val_mae: 769.7708 - val_yearerr: 45589.6641\n",
      "Epoch 5/10\n",
      "87672/87672 [==============================] - 6s 69us/step - loss: 336230.0640 - mae: 452.2625 - yearerr: 12647.7910 - val_loss: 1080473.0013 - val_mae: 846.7266 - val_yearerr: 51545.2734\n",
      "Epoch 6/10\n",
      "87672/87672 [==============================] - 6s 73us/step - loss: 325651.3222 - mae: 444.8640 - yearerr: 12231.6367 - val_loss: 806345.2454 - val_mae: 707.6595 - val_yearerr: 41107.2773\n",
      "Epoch 7/10\n",
      "87672/87672 [==============================] - 6s 74us/step - loss: 322272.3293 - mae: 442.3202 - yearerr: 12337.0176 - val_loss: 856040.7087 - val_mae: 734.4001 - val_yearerr: 43163.2617\n",
      "Epoch 8/10\n",
      "87672/87672 [==============================] - 6s 74us/step - loss: 317404.5574 - mae: 438.8831 - yearerr: 12091.4365 - val_loss: 702700.8409 - val_mae: 652.7498 - val_yearerr: 37065.5273\n",
      "Epoch 9/10\n",
      "87672/87672 [==============================] - 6s 73us/step - loss: 313922.3973 - mae: 435.4631 - yearerr: 11820.1836 - val_loss: 745178.0537 - val_mae: 674.8754 - val_yearerr: 38679.3438\n",
      "Epoch 10/10\n",
      "87672/87672 [==============================] - 6s 69us/step - loss: 307660.3216 - mae: 431.3095 - yearerr: 11358.2705 - val_loss: 933919.2161 - val_mae: 778.6973 - val_yearerr: 46625.8984\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#for year in np.arange(2004,2017)\n",
    "\n",
    "ymaelist = []\n",
    "maelist = []\n",
    "\n",
    "year = 2004 # year to read\n",
    "np.arange(2004,2017)\n",
    "\n",
    "\n",
    "\n",
    "pwd = \"/home/jasperzhang/Documents/elec/\"  #data directory path\n",
    "\n",
    "xtrain = pd.read_csv(pwd + \"xtrain\" + str(year) + \".csv\")\n",
    "ytrain = pd.read_csv(pwd + \"ytrain\" + str(year) + \".csv\")\n",
    "\n",
    "xtest = pd.read_csv(pwd + \"xtest\" + str(year) + \".csv\")\n",
    "ytest = pd.read_csv(pwd + \"ytest\" + str(year) + \".csv\")\n",
    "\n",
    "\n",
    "xval = pd.read_csv(pwd + \"xval\" + str(year) + \".csv\")\n",
    "yval = pd.read_csv(pwd + \"yval\" + str(year) + \".csv\")\n",
    "\n",
    "\n",
    "#data normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "#scale selected columns\n",
    "def scaleColumns(df, cols_to_scale):\n",
    "\n",
    "    for col in cols_to_scale:\n",
    "\n",
    "        df[col] = pd.DataFrame(sc.fit_transform(pd.DataFrame(df[col])),columns=[col])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#normalize weather variables\n",
    "train_x = scaleColumns(xtrain,['precipitation','temperature','irradiance_surface','irradiance_toa','snowfall','snowfall','snow_depth','cloud_cover','air_density'])\n",
    "val_x = scaleColumns(xval,['precipitation','temperature','irradiance_surface','irradiance_toa','snowfall','snowfall','snow_depth','cloud_cover','air_density'])\n",
    "test_x = scaleColumns(xtest,['precipitation','temperature','irradiance_surface','irradiance_toa','snowfall','snowfall','snow_depth','cloud_cover','air_density'])\n",
    "train_y = ytrain\n",
    "val_y = yval\n",
    "test_y = ytest\n",
    "\n",
    "#hyperparameters\n",
    "n_input = xtrain.shape[1]\n",
    "n_hidden_1 = n_input * 2  \n",
    "n_hidden_2 = n_input * 4 \n",
    "n_hidden_3 = n_input * 2 \n",
    "n_classes = 1 \n",
    "training_epochs = 10\n",
    "batch_size = 64  \n",
    "\n",
    "\n",
    "#model\n",
    "model = Sequential()\n",
    "model.add(Dense(n_hidden_1, activation='relu', input_dim=n_input)) \n",
    "model.add(Dense(n_hidden_2, activation='relu'))\n",
    "model.add(Dense(n_hidden_3, activation='relu'))\n",
    "model.add(Dense(n_classes)) \n",
    "\n",
    "\n",
    "#define our own performance evaluation year error\n",
    "import keras.backend as K\n",
    "def yearerr(y_true, y_pred):\n",
    "    a = K.sum(y_true) - K.sum(y_pred)\n",
    "    b = K.abs(a)\n",
    "    return b\n",
    "\n",
    "#compile\n",
    "model.compile(loss='mse', optimizer='rmsprop', metrics=['mae',yearerr])\n",
    "\n",
    "\n",
    "fit = model.fit(train_x, train_y, batch_size=batch_size, epochs=training_epochs,  validation_data=(test_x, test_y))\n",
    "\n",
    "pred_y = model.predict(val_x)\n",
    "\n",
    "def maeyear(a,b):\n",
    "    ymae = np.abs(np.sum(a) - np.sum(b))\n",
    "    return ymae\n",
    "\n",
    "def mae(a,b):\n",
    "    ymae = np.mean(np.abs(a-b))\n",
    "    return ymae\n",
    "\n",
    "pred_mae = mae(yval, pred_y)\n",
    "pred_ymae = maeyear(yval, pred_y)\n",
    "\n",
    "maelist.append(pred_mae)\n",
    "ymaelist.append(pred_ymae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
